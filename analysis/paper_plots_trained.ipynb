{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Paper Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_model_helpers import *\n",
    "sys.path.append(os.path.join('..'))\n",
    "from models.func_to_func2d_invasive import FNO2d\n",
    "from util.utilities_module import *\n",
    "from gen_GRF import *\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set plot defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot defaults\n",
    "# Set font default\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'custom'\n",
    "CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "                  '#999999', '#e41a1c', '#dede00',\n",
    "                    '#000000']\n",
    "matplotlib.rcParams['mathtext.rm'] = 'stix'\n",
    "matplotlib.rcParams['mathtext.it'] = 'stix'\n",
    "matplotlib.rcParams['mathtext.bf'] = 'stix'\n",
    "\n",
    "\n",
    "matplotlib.rcParams[\"axes.formatter.limits\"] = (-99, 99) #makes scientific notation threshold high\n",
    "plt.rcParams['font.family'] = 'serif'  # or 'DejaVu Serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman']  # 'DejaVu Serif' 'serif' 'Times\n",
    "\n",
    "tickfontsize = 40\n",
    "fontsize = 40\n",
    "linewidth = 4\n",
    "markersize = 15\n",
    "\n",
    "SMALL_SIZE = tickfontsize\n",
    "MEDIUM_SIZE = tickfontsize\n",
    "BIGGER_SIZE = fontsize\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "shapes = ['o','s','^','D','*', 'x', 'P', 'h', 'v', '<', '>', 'X', 'd', 'p', '|', '_', '.', ',']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_vals = [0.5, 1.0, 1.5, 2.0]\n",
    "sizes = [64, 128, 256, 512] #, 1024]\n",
    "plot_sizes = sizes[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error evaluation function for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_err_norms_trained(s,model_name, sizes = [32, 64, 128, 256],dup_input = True):\n",
    "\n",
    "    model_info_path = '../models/trained_models/' + model_name + '_info.yaml'\n",
    "    model_path = '../models/trained_models/' + model_name + '.pt'\n",
    "\n",
    "    samp_count_input = 2\n",
    "    true_size = sizes[-1]\n",
    "  \n",
    "    # Load model\n",
    "    model = load_model(model_info_path, model_path,s_outputspace = (true_size,true_size))\n",
    "    model_info = load_model_info(model_info_path)\n",
    "    n_layers = model_info['n_layers']-1\n",
    "\n",
    "    true_norms = torch.zeros(n_layers, samp_count_input)\n",
    "    all_err = torch.zeros(len(sizes)-1,n_layers, samp_count_input)\n",
    "\n",
    "    if dup_input:\n",
    "        channel_count = 3\n",
    "    else:\n",
    "        channel_count = 1\n",
    "    true_inputs = torch.zeros(samp_count_input,channel_count,true_size,true_size)\n",
    "    for input_i in range(samp_count_input):\n",
    "        true_input_path = '../data/GRF_s' + str(s) +'_GRF_size_' + str(true_size) + '_' + str(input_i)+ '.pkl'\n",
    "        input_true = load_data(true_input_path)\n",
    "        input_true = input_true.unsqueeze(0).unsqueeze(0)\n",
    "        if dup_input:\n",
    "            # duplicate along axis 1\n",
    "            input_true = input_true.repeat(1,3,1,1)\n",
    "            # set middle channel to 0\n",
    "            input_true[:,1] = 0\n",
    "        else:\n",
    "            pass\n",
    "        true_inputs[input_i,:] = input_true\n",
    "    \n",
    "    layers_true = get_layer_output(model,true_inputs)\n",
    "\n",
    "    for size_i, size in enumerate(sizes[:-1]):\n",
    "        disc_inputs = torch.zeros(samp_count_input,channel_count,size,size)\n",
    "        for input_i in range(samp_count_input):\n",
    "            disc_input_path = '../data/GRF_s' +str(s) + f'_GRF_size_{size}_'+ str(input_i)+'.pkl'\n",
    "            input_disc = load_data(disc_input_path)\n",
    "            input_disc = input_disc.unsqueeze(0).unsqueeze(0)\n",
    "            if dup_input:\n",
    "                input_disc = input_disc.repeat(1,3,1,1)\n",
    "                input_disc[:,1] = 0\n",
    "            else:\n",
    "                pass\n",
    "            disc_inputs[input_i,:] = input_disc\n",
    "        layers_disc = get_layer_output(model,disc_inputs)\n",
    "        for input_i in range(samp_count_input):\n",
    "            for layer in range(n_layers):\n",
    "                err = torch.norm(layers_disc[layer][input_i] - layers_true[layer][input_i])\n",
    "                all_err[size_i,layer, input_i] = err\n",
    "                true_norms[layer, input_i] = torch.norm(layers_true[layer][input_i])\n",
    "\n",
    "    all_err = all_err.detach().numpy()\n",
    "    true_norms = true_norms.detach().numpy()\n",
    "    all_err = all_err.reshape(len(sizes)-1,n_layers,samp_count_input)\n",
    "\n",
    "    return all_err, true_norms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_trained(model_name,s_vals,sizes):\n",
    "    all_err_s = []\n",
    "    true_norms_s = []\n",
    "    for s in s_vals:\n",
    "        all_err, true_norms = get_err_norms_trained(s,model_name,sizes=sizes)\n",
    "        all_err_s.append(all_err)\n",
    "        true_norms_s.append(true_norms)\n",
    "\n",
    "    true_norms_s = np.array(true_norms_s)\n",
    "    all_err_s = np.array(all_err_s)\n",
    "    return all_err_s, true_norms_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_err(all_err_s,true_norms_s):\n",
    "    # Normalize all_err_s by true_norms_s\n",
    "    n_layers = true_norms_s.shape[1]\n",
    "    all_err_s = np.array(all_err_s)\n",
    "    n_samples = all_err_s.shape[-1]\n",
    "    all_err_s_norm = np.zeros((len(s_vals),len(plot_sizes),n_layers,n_samples))\n",
    "    for i in range(len(s_vals)):\n",
    "        for j in range(n_layers):\n",
    "            all_err_s_norm[i,:,j,:] = all_err_s[i,:,j,:] / true_norms_s[i,j,0]\n",
    "    return all_err_s_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_err_vs_N(all_err_s_norm,plot_sizes,plot_name):\n",
    "    fix, ax = plt.subplots(1,4, figsize=(40, 10))\n",
    "\n",
    "    for i, s in enumerate(s_vals):\n",
    "        all_err = all_err_s_norm[i]\n",
    "\n",
    "        all_err_mean = np.mean(all_err, axis = -1)\n",
    "        all_err_std = 2*np.std(all_err, axis = -1)\n",
    "\n",
    "        slopes = []\n",
    "\n",
    "        for layer in range(all_err.shape[1]):\n",
    "            ax[i].plot(plot_sizes,all_err_mean[:,layer],label = f'Layer {layer+1}',color = CB_color_cycle[layer],marker = shapes[layer],linewidth = linewidth,markersize = markersize)\n",
    "            ax[i].errorbar(plot_sizes, all_err_mean[:,layer], yerr=all_err_std[:,layer],color = CB_color_cycle[layer])\n",
    "            ax[i].fill_between(plot_sizes, all_err_mean[:,layer] - all_err_std[:,layer], all_err_mean[:,layer] + all_err_std[:,layer], alpha=0.2, color = CB_color_cycle[layer])\n",
    "\n",
    "            p = np.polyfit(np.log(plot_sizes), np.log(all_err_mean[:,layer]), 1)\n",
    "            slopes.append(p[0])\n",
    "\n",
    "        ax[i].set_title('s = ' + str(s) + f',    Average Slope = {np.mean(slopes):.2f}') \n",
    "        # logscale\n",
    "        ax[i].set_yscale('log')\n",
    "        # set y range\n",
    "        ax[i].set_ylim([np.min(all_err_s_norm)/2, np.max(all_err_s_norm)*2])\n",
    "        ax[i].set_xscale('log') \n",
    "        ax[i].set_xlabel('N')\n",
    "        ax[i].set_xticks([])\n",
    "        ax[i].xaxis.set_minor_locator(plt.NullLocator())\n",
    "\n",
    "        # no scientific notation x labels\n",
    "\n",
    "        ax[i].set_xticks(plot_sizes, plot_sizes)\n",
    "    ax[0].set_ylabel('Relative Error') \n",
    "    ax[0].legend()\n",
    "    ax[3].legend()\n",
    "    # save figure\n",
    "    plt.savefig('../Figures/' + plot_name + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smooth Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X-Y Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file\n",
    "config_name = 'smooth_x_y_grid'\n",
    "config_path = '../models/trained_models/' + config_name + '_info.yaml'\n",
    "with open(config_path, 'r') as file:\n",
    "    config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "# Load input and output data\n",
    "input_data_smooth = torch.load('../data/smooth_training_data/A_to_chi1_tiny_input_data.pt')\n",
    "output_data_smooth = torch.load('../data/smooth_training_data/A_to_chi1_tiny_output_data.pt')\n",
    "\n",
    "model_name = config['model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Research/Bound FNO Discretization Error/BoundFNO/analysis/eval_model_helpers.py:91\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_info_path, model_path, s_outputspace)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 91\u001b[0m     model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(model_path, map_location\u001b[39m=\u001b[39mdevice)[\u001b[39m'\u001b[39m\u001b[39mmodel_state_dict\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     92\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1671\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1670\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 1671\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1672\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1673\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for FNO2d:\n\tsize mismatch for fc0.weight: copying a param with shape torch.Size([64, 3]) from checkpoint, the shape in current model is torch.Size([64, 5]).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/margaret/Documents/Research/Bound FNO Discretization Error/BoundFNO/analysis/paper_plots_trained.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/margaret/Documents/Research/Bound%20FNO%20Discretization%20Error/BoundFNO/analysis/paper_plots_trained.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m all_err_s_xy, true_norms_s_xy \u001b[39m=\u001b[39m evaluate_model_trained(model_name,s_vals,sizes)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/margaret/Documents/Research/Bound%20FNO%20Discretization%20Error/BoundFNO/analysis/paper_plots_trained.ipynb#X54sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m all_err_s_norm_xy \u001b[39m=\u001b[39m normalize_err(all_err_s_xy,true_norms_s_xy)\n",
      "\u001b[1;32m/Users/margaret/Documents/Research/Bound FNO Discretization Error/BoundFNO/analysis/paper_plots_trained.ipynb Cell 16\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/margaret/Documents/Research/Bound%20FNO%20Discretization%20Error/BoundFNO/analysis/paper_plots_trained.ipynb#X54sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m true_norms_s \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/margaret/Documents/Research/Bound%20FNO%20Discretization%20Error/BoundFNO/analysis/paper_plots_trained.ipynb#X54sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m s_vals:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/margaret/Documents/Research/Bound%20FNO%20Discretization%20Error/BoundFNO/analysis/paper_plots_trained.ipynb#X54sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     all_err, true_norms \u001b[39m=\u001b[39m get_err_norms_trained(s,model_name,sizes\u001b[39m=\u001b[39msizes)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/margaret/Documents/Research/Bound%20FNO%20Discretization%20Error/BoundFNO/analysis/paper_plots_trained.ipynb#X54sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     all_err_s\u001b[39m.\u001b[39mappend(all_err)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/margaret/Documents/Research/Bound%20FNO%20Discretization%20Error/BoundFNO/analysis/paper_plots_trained.ipynb#X54sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     true_norms_s\u001b[39m.\u001b[39mappend(true_norms)\n",
      "\u001b[1;32m/Users/margaret/Documents/Research/Bound FNO Discretization Error/BoundFNO/analysis/paper_plots_trained.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/margaret/Documents/Research/Bound%20FNO%20Discretization%20Error/BoundFNO/analysis/paper_plots_trained.ipynb#X54sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m true_size \u001b[39m=\u001b[39m sizes[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/margaret/Documents/Research/Bound%20FNO%20Discretization%20Error/BoundFNO/analysis/paper_plots_trained.ipynb#X54sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Load model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/margaret/Documents/Research/Bound%20FNO%20Discretization%20Error/BoundFNO/analysis/paper_plots_trained.ipynb#X54sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model \u001b[39m=\u001b[39m load_model(model_info_path, model_path,s_outputspace \u001b[39m=\u001b[39m (true_size,true_size))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/margaret/Documents/Research/Bound%20FNO%20Discretization%20Error/BoundFNO/analysis/paper_plots_trained.ipynb#X54sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m model_info \u001b[39m=\u001b[39m load_model_info(model_info_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/margaret/Documents/Research/Bound%20FNO%20Discretization%20Error/BoundFNO/analysis/paper_plots_trained.ipynb#X54sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m n_layers \u001b[39m=\u001b[39m model_info[\u001b[39m'\u001b[39m\u001b[39mn_layers\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Research/Bound FNO Discretization Error/BoundFNO/analysis/eval_model_helpers.py:93\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_info_path, model_path, s_outputspace)\u001b[0m\n\u001b[1;32m     91\u001b[0m     model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(model_path, map_location\u001b[39m=\u001b[39mdevice)[\u001b[39m'\u001b[39m\u001b[39mmodel_state_dict\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     92\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(model_path))\n\u001b[1;32m     94\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m     95\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:789\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    787\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    788\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m    790\u001b[0m \u001b[39mif\u001b[39;00m weights_only:\n\u001b[1;32m    791\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:1131\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1129\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1130\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1131\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39mload()\n\u001b[1;32m   1133\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1135\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:1101\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m loaded_storages:\n\u001b[1;32m   1100\u001b[0m     nbytes \u001b[39m=\u001b[39m numel \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1101\u001b[0m     load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[1;32m   1103\u001b[0m \u001b[39mreturn\u001b[39;00m loaded_storages[key]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:1083\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1079\u001b[0m storage \u001b[39m=\u001b[39m zip_file\u001b[39m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[39m.\u001b[39mUntypedStorage)\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39muntyped()\n\u001b[1;32m   1080\u001b[0m \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[39m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1082\u001b[0m loaded_storages[key] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1083\u001b[0m     wrap_storage\u001b[39m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   1084\u001b[0m     dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:215\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 215\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[1;32m    216\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:182\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    181\u001b[0m     \u001b[39mif\u001b[39;00m location\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 182\u001b[0m         device \u001b[39m=\u001b[39m validate_cuda_device(location)\n\u001b[1;32m    183\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m_torch_load_uninitialized\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    184\u001b[0m             \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:166\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    163\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_get_device_index(location, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    165\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m--> 166\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAttempting to deserialize object on a CUDA \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    168\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mIf you are running on a CPU-only machine, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    169\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mcpu\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    170\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mto map your storages to the CPU.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    171\u001b[0m device_count \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "all_err_s_xy, true_norms_s_xy = evaluate_model_trained(model_name,s_vals,sizes)\n",
    "all_err_s_norm_xy = normalize_err(all_err_s_xy,true_norms_s_xy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
